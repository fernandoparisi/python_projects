# **üöÄNASA Turbofan Jet Engine**
# Predicci√≥n de Vida √ötil Restante (RUL) en Motores Turbofan

## Descripci√≥n del Proyecto

Este repositorio contiene un proyecto de Machine Learning centrado en la predicci√≥n de la **Vida √ötil Restante (Remaining Useful Life - RUL)** de motores turbofan. El objetivo es estimar cu√°ntos ciclos operativos le quedan a un motor antes de una falla funcional, utilizando datos de sensores operativos. Este tipo de predicci√≥n es crucial para el mantenimiento predictivo, permitiendo optimizar los tiempos de servicio y reducir costos operativos.

El an√°lisis se realiza sobre el dataset **FD001** de la serie CMAPSS (Commercial Modular Aero-Propulsion System Simulation) de la NASA, un benchmark est√°ndar en el campo del pron√≥stico de salud de sistemas.

## Contenido del Repositorio

-   `notebooks/`: Contiene los notebooks de Jupyter con el an√°lisis exploratorio de datos (EDA), preprocesamiento, entrenamiento de modelos, evaluaci√≥n y visualizaci√≥n.
    -   `NASA 0001.ipynb` 
-   `data/`:  `train_FD001.txt`, `test_FD001.txt` y `RUL_FD001`

## Modelos Evaluados

Se evalu√≥ un conjunto diverso de modelos de Machine Learning, incluyendo:

-   Regresi√≥n Lineal
-   K-Nearest Neighbors (KNN)
-   Random Forest
-   Gradient Boosting
-   XGBoost
-   LightGBM

## Conclusiones Clave

El an√°lisis revel√≥ insights importantes sobre el rendimiento de los modelos en la predicci√≥n del RUL:

-   **Sobreajuste (Overfitting) Predominante:** Modelos como **Random Forest y LightGBM** mostraron un sobreajuste significativo, rindiendo casi perfectamente en entrenamiento, pero cayendo dr√°sticamente en precisi√≥n en el conjunto de prueba (R¬≤ ‚âà 0.32-0.34).
-   **Potencial de los Modelos de Boosting:** **Gradient Boosting y XGBoost** demostraron el mejor rendimiento inicial en el conjunto de prueba (R¬≤ ‚âà 0.37-0.38), con predicciones visualmente m√°s cercanas a los valores reales. Esto los posiciona como los candidatos m√°s prometedores para una optimizaci√≥n.
-   **Desaf√≠o en RULs Altos:** Una observaci√≥n consistente es la mayor dificultad para predecir con precisi√≥n RULs altos (motores en fases iniciales/sanas de su vida √∫til), un desaf√≠o com√∫n en este tipo de problemas.
-   **Disparidad en Distribuciones:** La distribuci√≥n del RUL real difiere entre los conjuntos de entrenamiento (m√°s concentrado en RULs bajos) y prueba (mayor proporci√≥n de RULs altos), lo que influye en el comportamiento del modelo.

## Pr√≥ximos Pasos

Para mejorar la precisi√≥n y la capacidad de generalizaci√≥n del modelo, los siguientes pasos son cruciales:

1.  **Ajuste de Hiperpar√°metros:** Optimizar los modelos de boosting (Gradient Boosting, XGBoost).
2.  **Ingenier√≠a de Caracter√≠sticas Avanzada:** Desarrollar nuevas caracter√≠sticas a partir de los datos de los sensores para mejorar la se√±al de degradaci√≥n.
3.  **An√°lisis mediante Redes Neuronales:** Aplicar modelos de LSTM para aprovechar su capacidad en datos secuenciales.

---

# Remaining Useful Life (RUL) Prediction for Turbofan Engines

## Project Description

This repository contains a Machine Learning project focused on predicting the **Remaining Useful Life (RUL)** of turbofan engines. The objective is to estimate how many operational cycles an engine has left before a functional failure, using operational sensor data. This type of prediction is crucial for predictive maintenance, enabling optimization of service times and reduction of operational costs.

The analysis is performed on the **FD001** dataset from NASA's CMAPSS (Commercial Modular Aero-Propulsion System Simulation) series, a standard benchmark in the field of system health prognostics.

## Repository Contents

-   `notebooks/`: Contains Jupyter notebooks with exploratory data analysis (EDA), preprocessing, model training, evaluation, and visualization.
    -   `NASA 0001.ipynb`
-   `data/`: Includes `train_FD001.txt`, `test_FD001.txt`, and `RUL_FD001.txt` (assuming `RUL_FD001` refers to a `.txt` file, please adjust if it's another format).

## Models Evaluated

A diverse set of Machine Learning models were evaluated, including:

-   Linear Regression
-   K-Nearest Neighbors (KNN)
-   Random Forest
-   Gradient Boosting
-   XGBoost
-   LightGBM

## Key Conclusions

The analysis revealed important insights into the models' performance in RUL prediction:

-   **Predominant Overfitting:** Models such as **Random Forest and LightGBM** showed significant overfitting. Despite their high training performance, they exhibited a sharp drop in accuracy on the test set (R¬≤ ‚âà 0.32-0.34).
-   **Potential of Boosting Models:** **Gradient Boosting and XGBoost** demonstrated the best initial performance on the test set (R¬≤ ‚âà 0.37-0.38), with visually closer predictions to actual values. This positions them as the most promising candidates for optimization.
-   **Challenge with High RULs:** A consistent observation is the increased difficulty in accurately predicting high RULs (engines in early/healthy phases of their lifespan), a common challenge in this type of problem.
-   **Distribution Disparity:** The actual RUL distribution differs between the training set (more concentrated at low RULs) and the test set (a higher proportion of high RULs), which influences model behavior.

## Next Steps

To improve model accuracy and generalization capability, the following steps are crucial:

1.  **Hyperparameter Tuning:** Optimize boosting models (Gradient Boosting, XGBoost).
2.  **Advanced Feature Engineering:** Develop new features from sensor data to enhance the degradation signal.
3.  **Neural Network Analysis:** Apply LSTM models to leverage their capability with sequential data.
